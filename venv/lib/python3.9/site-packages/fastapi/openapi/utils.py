# app_server.py
import os
import uuid
import hashlib
import tempfile
import asyncio
import traceback
from typing import Optional

from fastapi import FastAPI, UploadFile, File as UploadFileField, HTTPException, Query, Depends, Header, Request
from fastapi.responses import JSONResponse, StreamingResponse, Response
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST

from sqlalchemy import select, update, func
from database import engine, SessionLocal, Base
from models import FileModel, FileVersionModel

from minio import Minio
import botocore.exceptions  # sometimes useful for catching errors

# --- Config ---
SERVER_NAME = os.environ.get("SERVER_NAME", "app1")
MINIO_BUCKET = os.environ.get("MINIO_BUCKET", "files")
API_KEY = os.environ.get("API_KEY", "supersecretkey")

MINIO_ENDPOINT = os.environ.get("MINIO_ENDPOINT", "minio:9000")
MINIO_ACCESS_KEY = os.environ.get("MINIO_ACCESS_KEY", "minioadmin")
MINIO_SECRET_KEY = os.environ.get("MINIO_SECRET_KEY", "minioadmin")
MINIO_SECURE = os.environ.get("MINIO_SECURE", "false").lower() in ("1", "true", "yes")

# --- MinIO client (sync) ---
minio_client = Minio(
    MINIO_ENDPOINT,
    access_key=MINIO_ACCESS_KEY,
    secret_key=MINIO_SECRET_KEY,
    secure=MINIO_SECURE,
)

# --- Prometheus metrics ---
REQUEST_COUNT = Counter("file_requests_total", "Total HTTP requests", ["method", "endpoint", "status"])
REQUEST_LATENCY = Histogram("file_request_latency_seconds", "Request latency seconds", ["endpoint"])

app = FastAPI(title="File Repository")


# --- Middleware: metrics & robust logging ---
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start = asyncio.get_event_loop().time()
    endpoint = request.url.path
    method = request.method
    status_code = "500"
    try:
        response = await call_next(request)
        status_code = str(response.status_code)
        return response
    except Exception as exc:
        # ensure metrics get recorded for exceptions too
        # log the traceback
        traceback.print_exc()
        raise
    finally:
        duration = asyncio.get_event_loop().time() - start
        # prometheus labels should be strings
        REQUEST_COUNT.labels(method=method, endpoint=endpoint, status=status_code).inc()
        REQUEST_LATENCY.labels(endpoint=endpoint).observe(duration)
        print(f"{method} {endpoint} {status_code} - {duration:.4f}s")


# --- API key dependency ---
async def verify_api_key(x_api_key: Optional[str] = Header(None)):
    if x_api_key != API_KEY:
        raise HTTPException(status_code=401, detail="Unauthorized")


# --- Startup: create DB tables and ensure MinIO bucket exists ---
@app.on_event("startup")
async def startup_event():
    # create tables
    async with engine.begin() as conn:
        await conn.run_sync(Base.metadata.create_all)

    # ensure MinIO bucket exists (run in thread to avoid blocking)
    def ensure_bucket():
        try:
            if not minio_client.bucket_exists(MINIO_BUCKET):
                minio_client.make_bucket(MINIO_BUCKET)
                print(f"Created MinIO bucket: {MINIO_BUCKET}")
            else:
                print(f"Bucket exists: {MINIO_BUCKET}")
        except Exception as e:
            # print but allow the app to start; readiness probe will fail until bucket is available
            print("MinIO bucket check/create error:", e)
            traceback.print_exc()

    await asyncio.to_thread(ensure_bucket)


# --- Prometheus endpoint ---
@app.get("/metrics")
def metrics():
    data = generate_latest()
    return Response(content=data, media_type=CONTENT_TYPE_LATEST)


# --- Health / readiness ---
@app.get("/healthz")
async def health_check():
    """Return 200 only if DB and MinIO are reachable."""
    status = {"status": "ok", "db": "unknown", "minio": "unknown", "server": SERVER_NAME}
    # check DB connectivity
    try:
        async with SessionLocal() as session:
            # simple lightweight query
            await session.execute(select(func.now()))
        status["db"] = "ok"
    except Exception as e:
        status["db"] = f"error: {e}"

    # check MinIO connectivity
    try:
        # bucket_exists is blocking; run in thread
        exists = await asyncio.to_thread(minio_client.bucket_exists, MINIO_BUCKET)
        status["minio"] = "ok" if exists else "missing_bucket"
    except Exception as e:
        status["minio"] = f"error: {e}"

    if status["db"] == "ok" and status["minio"] == "ok":
        return status
    else:
        # useful for readiness probes: non-200 when not ready
        raise HTTPException(status_code=503, detail=status)


# --- Helpers for file uploads (non-blocking wrapper) ---
async def save_upload_to_tempfile(upload: UploadFile) -> str:
    """
    Save UploadFile to a temp file on disk using a thread to avoid blocking event loop.
    Returns the temporary filename (path). Caller must remove it.
    """
    fd, path = tempfile.mkstemp()
    os.close(fd)  # we'll write via standard open in thread

    async def _write_to_temp():
        # blocking I/O inside thread
        with open(path, "wb") as f:
            while True:
                chunk = await upload.read(64 * 1024)
                if not chunk:
                    break
                f.write(chunk)

    # run the coroutine that uses upload.read() which is async; so instead:
    # We'll read from upload in async, but write to file in a thread by passing bytes.
    # Simpler approach: read all async into chunks, then write in thread.
    chunks = []
    while True:
        chunk = await upload.read(64 * 1024)
        if not chunk:
            break
        chunks.append(chunk)

    def _blocking_write(chunks_local):
        with open(path, "wb") as f:
            for c in chunks_local:
                f.write(c)

    await asyncio.to_thread(_blocking_write, chunks)
    return path


async def compute_checksum_and_size(path: str):
    """Compute sha256 checksum and file size (run in thread)."""
    def _compute(p):
        h = hashlib.sha256()
        size = 0
        with open(p, "rb") as f:
            while True:
                chunk = f.read(64 * 1024)
                if not chunk:
                    break
                h.update(chunk)
                size += len(chunk)
        return h.hexdigest(), size
    return await asyncio.to_thread(_compute, path)


async def minio_fput(bucket: str, object_key: str, path: str):
    """Call blocking minio_client.fput_object in a thread."""
    return await asyncio.to_thread(minio_client.fput_object, bucket, object_key, path)


async def minio_get_object_stream(bucket: str, object_key: str):
    """
    Return an iterator/generator that yields bytes from MinIO object.
    We call get_object in a thread and then yield chunks in async-friendly way using to_thread.
    """
    # get_object returns a urllib3.response.HTTPResponse-like stream
    # retrieving object is blocking - do it in thread and return object; then read in thread too.
    def _get():
        return minio_client.get_object(bucket, object_key)

    obj = await asyncio.to_thread(_get)

    # create an async generator that reads from obj in threads
    async def stream_generator():
        try:
            while True:
                chunk = await asyncio.to_thread(obj.read, 64 * 1024)
                if not chunk:
                    break
                yield chunk
        finally:
            try:
                obj.close()
                obj.release_conn()
            except Exception:
                pass

    return stream_generator()


# --- Upload new file (requires API key) ---
@app.post("/v1/files", dependencies=[Depends(verify_api_key)])
async def upload_file(file: UploadFile = UploadFileField(...)):
    file_id = uuid.uuid4().hex
    version = 1
    object_key = f"{file_id}/v{version}"

    # 1) Save upload to temp file (non-blocking to event loop)
    tmp_path = await save_upload_to_tempfile(file)

    try:
        checksum, size = await compute_checksum_and_size(tmp_path)
        # 2) Upload to MinIO (blocking -> run in thread)
        try:
            await minio_fput(MINIO_BUCKET, object_key, tmp_path)
        except Exception as e:
            traceback.print_exc()
            raise HTTPException(status_code=500, detail=f"MinIO upload failed: {e}")

        # 3) Insert metadata in DB inside one transaction
        async with SessionLocal() as session:
            async with session.begin():
                # ensure uniqueness (simple check)
                existing = await session.execute(select(FileModel).where(FileModel.file_id == file_id))
                if existing.scalar_one_or_none():
                    raise HTTPException(status_code=409, detail="file id collision (try again)")

                new_file = FileModel(
                    file_id=file_id,
                    current_version=version,
                    path=object_key,
                )
                new_version = FileVersionModel(
                    file_id=file_id,
                    version=version,
                    object_key=object_key,
                    checksum=checksum,
                    size=size,
                )
                session.add_all([new_file, new_version])

        return JSONResponse(
            status_code=201,
            content={
                "file_id": file_id,
                "path": object_key,
                "version": version,
                "checksum": checksum,
                "size": size,
                "server": SERVER_NAME,
            },
        )
    finally:
        # cleanup tmp file
        try:
            os.unlink(tmp_path)
        except Exception:
            pass


# --- Upload a new version ---
@app.put("/v1/files/{file_id}", dependencies=[Depends(verify_api_key)])
async def upload_new_version(file_id: str, file: UploadFile = UploadFileField(...)):
    # Save to temp
    tmp_path = await save_upload_to_tempfile(file)
    try:
        checksum, size = await compute_checksum_and_size(tmp_path)

        # Use a transaction that reads current_version and updates in same tx
        async with SessionLocal() as session:
            async with session.begin():
                res = await session.execute(select(FileModel).where(FileModel.file_id == file_id).with_for_update())
                row = res.scalar_one_or_none()
                if not row:
                    raise HTTPException(status_code=404, detail="file not found")
                curr_version = row.current_version
                new_version_num = curr_version + 1
                object_key = f"{file_id}/v{new_version_num}"

                # Upload object first
                try:
                    await minio_fput(MINIO_BUCKET, object_key, tmp_path)
                except Exception as e:
                    traceback.print_exc()
                    raise HTTPException(status_code=500, detail=f"MinIO upload failed: {e}")

                # record version and update file row
                new_version_obj = FileVersionModel(
                    file_id=file_id,
                    version=new_version_num,
                    object_key=object_key,
                    checksum=checksum,
                    size=size,
                )
                session.add(new_version_obj)
                await session.execute(
                    update(FileModel)
                    .where(FileModel.file_id == file_id)
                    .values(current_version=new_version_num)
                )

        return {
            "file_id": file_id,
            "version": new_version_num,
            "checksum": checksum,
            "size": size,
            "server": SERVER_NAME,
        }
    finally:
        try:
            os.unlink(tmp_path)
        except Exception:
            pass


# --- Download file ---
@app.get("/v1/files/{file_id}")
async def download_file(file_id: str, version: Optional[int] = Query(None)):
    async with SessionLocal() as session:
        async with session.begin():
            if version is None:
                res = await session.execute(select(FileModel).where(FileModel.file_id == file_id))
                row = res.scalar_one_or_none()
                if not row:
                    raise HTTPException(status_code=404, detail="file not found")
                version = row.current_version

            res = await session.execute(
                select(FileVersionModel).where(
                    (FileVersionModel.file_id == file_id) & (FileVersionModel.version == version)
                )
            )
            vrow = res.scalar_one_or_none()
            if not vrow:
                raise HTTPException(status_code=404, detail="file version not found")

            stream = await minio_get_object_stream(MINIO_BUCKET, vrow.object_key)
            filename = f"{file_id}_v{version}"

            return StreamingResponse(
                stream,
                media_type="application/octet-stream",
                headers={"Content-Disposition": f'attachment; filename="{filename}"'},
            )


# --- Delete file (soft delete + remove objects from MinIO) ---
@app.delete("/v1/files/{file_id}", dependencies=[Depends(verify_api_key)])
async def delete_file(file_id: str):
    async with SessionLocal() as session:
        async with session.begin():
            res = await session.execute(select(FileModel).where(FileModel.file_id == file_id))
            row = res.scalar_one_or_none()
            if not row:
                raise HTTPException(status_code=404, detail="file not found")

            versions_res = await session.execute(select(FileVersionModel).where(FileVersionModel.file_id == file_id))
            versions = versions_res.scalars().all()

            # remove objects from MinIO (do in threads in parallel)
            async def _remove_object(object_key: str):
                try:
                    await asyncio.to_thread(minio_client.remove_object, MINIO_BUCKET, object_key)
                except Exception as e:
                    print("MinIO remove_object error:", e)

            await asyncio.gather(*[_remove_object(v.object_key) for v in versions])

            # soft-delete file and delete version rows
            await session.execute(update(FileModel).where(FileModel.file_id == file_id).values(deleted=True))
            await session.execute(FileVersionModel.__table__.delete().where(FileVersionModel.file_id == file_id))

    return {"status": "deleted", "file_id": file_id}
